{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "from asyncio import MultiLoopChildWatcher\n",
    "from doctest import OutputChecker\n",
    "\n",
    "from turtle import hideturtle\n",
    "import warnings\n",
    "\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define arguments manually\n",
    "arguments = argparse.Namespace()\n",
    "# device\n",
    "arguments.device = \"cuda\"\n",
    "\n",
    "# define arguments for model\n",
    "#arguments.model = \"ResNet18\" # ResNet not supported for structured\n",
    "arguments.model = \"LeNet5\"\n",
    "arguments.hidden_dim = None\n",
    "#arguments.input_dim = None # for ResNet\n",
    "arguments.input_dim = (1,1,1) # for LeNet5\n",
    "arguments.output_dim = 10\n",
    "arguments.disable_masking = 1 # 0 for disable mask, 1 for mask (unstructured)\n",
    "arguments.track_weights = 0\n",
    "arguments.enable_rewinding = 0\n",
    "arguments.growing_rate = 0.0000\n",
    "arguments.outer_layer_pruning = 1\n",
    "# arguments.prune_criterion = \"SNIPit\"  # unstructured\n",
    "\n",
    "arguments.prune_criterion = \"SNAPitDuring\" # or SNAPit ... # structured\n",
    "arguments.l0 = 0\n",
    "arguments.l0_reg = 1.0\n",
    "arguments.l1_reg = 0\n",
    "arguments.lp_reg = 0\n",
    "arguments.l2_reg = 5e-5\n",
    "arguments.hoyer_reg = 0.001\n",
    "arguments.N = 6000 # different for different dataset\n",
    "arguments.beta_ema = 0.999\n",
    "\n",
    "\n",
    "# define arguments for criterion\n",
    "arguments.pruning_limit = 0.7\n",
    "arguments.snip_steps = 6\n",
    "\n",
    "# not pre-trained model\n",
    "arguments.checkpoint_name = None\n",
    "arguments.checkpoint_model = None\n",
    "\n",
    "# dataset\n",
    "arguments.data_set = \"MNIST\"\n",
    "arguments.batch_size = 512\n",
    "arguments.mean = (0.1307,)\n",
    "arguments.std = (0.3081,)\n",
    "arguments.tuning = 0\n",
    "arguments.preload_all_data = 0\n",
    "arguments.random_shuffle_labels = 0\n",
    "\n",
    "# loss\n",
    "arguments.loss = \"CrossEntropy\"\n",
    "\n",
    "# optimizer\n",
    "arguments.optimizer = \"ADAM\"\n",
    "arguments.learning_rate = 2e-3\n",
    "\n",
    "# training\n",
    "arguments.save_freq = 1e6\n",
    "arguments.eval = 0\n",
    "arguments.train_scheme = \"DefaultTrainer\"\n",
    "arguments.seed = 1234\n",
    "arguments.epochs = 10\n",
    "\n",
    "arguments.grad_noise = 0\n",
    "arguments.grad_clip =10\n",
    "arguments.eval_freq = 1000\n",
    "arguments.max_training_minutes= 6120\n",
    "arguments.plot_weights_freq = 50\n",
    "arguments.prune_delay = 0\n",
    "arguments.prune_freq = 1\n",
    "arguments.rewind_to = 6\n",
    "\n",
    "arguments.skip_first_plot = 0\n",
    "arguments.disable_histograms = 0\n",
    "arguments.disable_saliency = 0\n",
    "arguments.disable_confusion = 0\n",
    "arguments.disable_weightplot = 0\n",
    "arguments.disable_netplot = 0\n",
    "arguments.disable_activations = 0\n",
    "\n",
    "arguments.pruning_rate = 0\n",
    "# during training\n",
    "arguments.pruning_freq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 2022-04-18_01.10.59\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics()\n",
    "out = metrics.log_line\n",
    "print = out\n",
    "\n",
    "ensure_current_directory()\n",
    "global out \n",
    "out = metrics.log_line\n",
    "out(f\"starting at {get_date_stamp()}\")\n",
    "\n",
    "metrics._batch_size = arguments.batch_size\n",
    "metrics._eval_freq = arguments.eval_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = configure_device(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR,arguments.model,\n",
    "        device=device,\n",
    "        hidden_dim = arguments.hidden_dim,\n",
    "        input_dim = arguments.input_dim,\n",
    "        output_dim = arguments.output_dim,\n",
    "        is_maskable=arguments.disable_masking,\n",
    "        is_tracking_weights=arguments.track_weights,\n",
    "        is_rewindable=arguments.enable_rewinding,\n",
    "        is_growable=arguments.growing_rate > 0,\n",
    "        outer_layer_pruning=arguments.outer_layer_pruning,\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments.outer_layer_pruning) and (\n",
    "                                           \"Structured\" in arguments.prune_criterion),\n",
    "        l0=arguments.l0,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        N=arguments.N,\n",
    "        beta_ema=arguments.beta_ema,\n",
    "        l2_reg=arguments.l2_reg\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 16, 5, 5])\n",
      "torch.Size([120])\n",
      "torch.Size([120])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 1080])\n",
      "torch.Size([84])\n",
      "torch.Size([84])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key,param in model.named_parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get criterion\n",
    "criterion = find_right_model(\n",
    "        CRITERION_DIR,arguments.prune_criterion,\n",
    "        model=model,\n",
    "        limit=arguments.pruning_limit,\n",
    "        start=0.5,\n",
    "        steps=arguments.snip_steps,\n",
    "        device=arguments.device\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(arguments, metrics, model):\n",
    "    if (not (arguments.checkpoint_name is None)) and (not (arguments.checkpoint_model is None)):\n",
    "        path = os.path.join(RESULTS_DIR, arguments.checkpoint_name, MODELS_DIR, arguments.checkpoint_model)\n",
    "        state = DATA_MANAGER.load_python_obj(path)\n",
    "        try:\n",
    "            model.load_state_dict(state)\n",
    "        except KeyError as e:\n",
    "            print(list(state.keys()))\n",
    "            raise e\n",
    "        out(f\"Loaded checkpoint {arguments.checkpoint_name} from {arguments.checkpoint_model}\")\n",
    "\n",
    "# load pre-trained weights if specified\n",
    "load_checkpoint(arguments, metrics, model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean (0.1307,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_loader, test_loader = find_right_model(\n",
    "        DATASETS, arguments.data_set,\n",
    "        arguments=arguments,\n",
    "        mean=arguments.mean,\n",
    "        std=arguments.std\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loss function\n",
    "loss = find_right_model(\n",
    "        LOSS_DIR, arguments.loss,\n",
    "        device=device,\n",
    "        l1_reg=arguments.l1_reg,\n",
    "        lp_reg=arguments.lp_reg,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        hoyer_reg=arguments.hoyer_reg\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimizer\n",
    "optimizer = find_right_model(\n",
    "        OPTIMS, arguments.optimizer,\n",
    "        params=model.parameters(),\n",
    "        lr=arguments.learning_rate,\n",
    "        weight_decay=arguments.l2_reg if not arguments.l0 else 0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made datestamp: 2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234\n"
     ]
    }
   ],
   "source": [
    "if not arguments.eval:\n",
    "    # build trainer\n",
    "    run_name = f'_model={arguments.model}_dataset={arguments.data_set}_prune-criterion={arguments.prune_criterion}' + \\\n",
    "               f'_pruning-limit={arguments.pruning_limit}_train-scheme={arguments.train_scheme}_seed={arguments.seed}'\n",
    "    trainer = find_right_model(\n",
    "            TRAINERS_DIR, arguments.train_scheme,\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            arguments=arguments,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            metrics=metrics,\n",
    "            criterion=criterion,\n",
    "            run_name = run_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mStarted training\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 0 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.0976562  |  2.5814126   |  2.5531989  | 0.1848920  |    0.0000000    |   0.0000000   |  0.0000000  |       15.3924092       |    1.9441691    |     666174.0000000      |      8.5328576      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      2931200.0       |     0.0054764     |\n",
      "Training... 117/118\n",
      "\n",
      "plotting..\n",
      "finished plotting\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 1 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9824219  |  0.0649967   |  0.0715947  | 0.9786420  |    0.0000000    |   0.0000000   |  0.0000000  |       15.3924092       |    9.7393245    |     666174.0000000      |      10.6084046     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      2931200.0       |     0.0073838     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 16 to 15\n",
      "pruning 150 percentage 0.0625 length_nonzero 2400\n",
      "trimming nodes in layer conv.8.weight from 120 to 26\n",
      "pruning 38250 percentage 0.796875 length_nonzero 48000\n",
      "trimming nodes in layer fc.1.weight from 84 to 61\n",
      "pruning 76446 percentage 0.8426587301587302 length_nonzero 90720\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 230 percentage 0.27380952380952384 length_nonzero 840\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 15.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(15.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(15.0, 26.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(26.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=234.0, out_features=61.0, bias=True)\n",
      "    (2): BatchNorm1d(61.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=61.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.8084813399280576\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 2 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.8183594  |  0.5561773   |  0.9337874  | 0.7344612  |    0.8093104    |   0.5221239   |  0.7700712  |       13.7354820       |   10.6441011    |     530723.0000000      |      10.8612524     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1784320.0       |     0.0083620     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 15 to 15\n",
      "pruning 0 percentage 0.0 length_nonzero 2250\n",
      "trimming nodes in layer conv.8.weight from 26 to 25\n",
      "pruning 375 percentage 0.038461538461538464 length_nonzero 9750\n",
      "trimming nodes in layer fc.1.weight from 61 to 43\n",
      "pruning 4599 percentage 0.32219419924337955 length_nonzero 14274\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 180 percentage 0.29508196721311475 length_nonzero 610\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 15.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(15.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(15.0, 25.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(25.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=225.0, out_features=43.0, bias=True)\n",
      "    (2): BatchNorm1d(43.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=43.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.18989020705917029\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 3 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9667969  |  0.2113294   |  0.1413243  | 0.9747243  |    0.8456539    |   0.6061947   |  0.9056134  |       13.5240480       |   10.5139306    |     525094.0000000      |      11.0186043     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1681920.0       |     0.0083529     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 15 to 14\n",
      "pruning 150 percentage 0.06666666666666667 length_nonzero 2250\n",
      "trimming nodes in layer conv.8.weight from 25 to 22\n",
      "pruning 1675 percentage 0.17866666666666667 length_nonzero 9375\n",
      "trimming nodes in layer fc.1.weight from 43 to 36\n",
      "pruning 2547 percentage 0.26325581395348835 length_nonzero 9675\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 70 percentage 0.16279069767441862 length_nonzero 430\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 22.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(22.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=198.0, out_features=36.0, bias=True)\n",
      "    (2): BatchNorm1d(36.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=36.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.2021940006372616\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 4 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9492188  |  0.2095268   |  0.1679547  | 0.9724897  |    0.8769391    |   0.6548673   |  0.9222461  |       13.2975697       |    9.7436976    |     502952.0000000      |      11.1295714     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1592320.0       |     0.0083666     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 14 to 14\n",
      "pruning 0 percentage 0.0 length_nonzero 2100\n",
      "trimming nodes in layer conv.8.weight from 22 to 22\n",
      "pruning 0 percentage 0.0 length_nonzero 7700\n",
      "trimming nodes in layer fc.1.weight from 36 to 31\n",
      "pruning 990 percentage 0.1388888888888889 length_nonzero 7128\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 50 percentage 0.1388888888888889 length_nonzero 360\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 22.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(22.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=198.0, out_features=31.0, bias=True)\n",
      "    (2): BatchNorm1d(31.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=31.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.0593742863667504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mEPOCH 5 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9746094  |  0.0982891   |  0.0525089  | 0.9874368  |    0.8842809    |   0.6769911   |  0.9330162  |       13.2360599       |   10.8410203    |     501787.0000000      |      11.2176924     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1571840.0       |     0.0083905     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 14 to 14\n",
      "pruning 0 percentage 0.0 length_nonzero 2100\n",
      "trimming nodes in layer conv.8.weight from 22 to 20\n",
      "pruning 700 percentage 0.09090909090909091 length_nonzero 7700\n",
      "trimming nodes in layer fc.1.weight from 31 to 31\n",
      "pruning 558 percentage 0.09090909090909091 length_nonzero 6138\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 20.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(20.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=180.0, out_features=31.0, bias=True)\n",
      "    (2): BatchNorm1d(31.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=31.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.07637666201202113\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 6 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9785156  |  0.0899044   |  0.0851199  | 0.9801126  |    0.8931331    |   0.6858407   |  0.9346035  |       13.1564981       |   11.5598961    |     500479.0000000      |      11.2907381     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1546240.0       |     0.0083938     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 14 to 14\n",
      "pruning 0 percentage 0.0 length_nonzero 2100\n",
      "trimming nodes in layer conv.8.weight from 20 to 20\n",
      "pruning 0 percentage 0.0 length_nonzero 7000\n",
      "trimming nodes in layer fc.1.weight from 31 to 29\n",
      "pruning 360 percentage 0.06451612903225806 length_nonzero 5580\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 20 percentage 0.06451612903225806 length_nonzero 310\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 20.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(20.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=180.0, out_features=29.0, bias=True)\n",
      "    (2): BatchNorm1d(29.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=29.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.02498192097823943\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 7 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9804688  |  0.0654836   |  0.0382858  | 0.9881204  |    0.8958169    |   0.6946903   |  0.9397075  |       13.1310654       |   10.3136269    |     500049.0000000      |      11.3531987     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1538560.0       |     0.0083915     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 14 to 14\n",
      "pruning 0 percentage 0.0 length_nonzero 2100\n",
      "trimming nodes in layer conv.8.weight from 20 to 20\n",
      "pruning 0 percentage 0.0 length_nonzero 7000\n",
      "trimming nodes in layer fc.1.weight from 29 to 29\n",
      "pruning 0 percentage 0.0 length_nonzero 5220\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 0 percentage 0.0 length_nonzero 290\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 20.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(20.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=180.0, out_features=29.0, bias=True)\n",
      "    (2): BatchNorm1d(29.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=29.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 8 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9824219  |  0.0615994   |  0.0352096  | 0.9885857  |    0.8958169    |   0.6946903   |  0.9399178  |       13.1310654       |    9.9757836    |     500049.0000000      |      11.4077954     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1538560.0       |     0.0084061     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "Saved results/2022-04-18_01.11.01_model=LeNet5_dataset=MNIST_prune-criterion=SNAPitDuring_pruning-limit=0.7_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "trimming nodes in layer conv.0.weight from 6 to 6\n",
      "pruning 0 percentage 0.0 length_nonzero 150\n",
      "trimming nodes in layer conv.4.weight from 14 to 14\n",
      "pruning 0 percentage 0.0 length_nonzero 2100\n",
      "trimming nodes in layer conv.8.weight from 20 to 19\n",
      "pruning 350 percentage 0.05 length_nonzero 7000\n",
      "trimming nodes in layer fc.1.weight from 29 to 29\n",
      "pruning 261 percentage 0.05 length_nonzero 5220\n",
      "set to zero but not removed because of input-output compatibility: 0 (0.0 features)\n",
      "pruning 0 percentage 0.0 length_nonzero 290\n",
      "  (conv): Sequential(\n",
      "    (0): ContainerConv2d(1.0, 6.0, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(6.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ContainerConv2d(6.0, 14.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(14.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ContainerConv2d(14.0, 19.0, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (9): BatchNorm2d(19.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (fc): Sequential(\n",
      "    (1): ContainerLinear(in_features=171.0, out_features=29.0, bias=True)\n",
      "    (2): BatchNorm1d(29.0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ContainerLinear(in_features=29.0, out_features=10.0, bias=True)\n",
      "final percentage after snap: 0.041203048081462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mEPOCH 9 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9863281  |  0.0393877   |  0.0387464  | 0.9890740  |    0.9001166    |   0.6991150   |  0.9425009  |       13.0889307       |   11.2752195    |     499413.0000000      |      11.4562303     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |      1525760.0       |     0.0083773     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "PRUNING...\n",
      "\n",
      "finished all pruning events already\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 5, 5])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([8, 3, 5, 5])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([6, 8, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([7, 54])\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "torch.Size([10, 7])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key,param in model.named_parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006026689625484288\n"
     ]
    }
   ],
   "source": [
    "# for unstructured calculating sparsity\n",
    "zero=0\n",
    "non_zero=0\n",
    "for weight in model.mask.values():\n",
    "    zero += torch.sum(weight==0).item()\n",
    "    non_zero += torch.sum(weight!=0).item()\n",
    "\n",
    "print(zero/(zero+non_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
