{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "from asyncio import MultiLoopChildWatcher\n",
    "from doctest import OutputChecker\n",
    "\n",
    "from turtle import hideturtle\n",
    "import warnings\n",
    "\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define arguments manually\n",
    "arguments = argparse.Namespace()\n",
    "# device\n",
    "arguments.device = \"cuda\"\n",
    "\n",
    "# define arguments for model\n",
    "arguments.model = \"ResNet18\"\n",
    "arguments.hidden_dim = None\n",
    "arguments.input_dim = None\n",
    "arguments.output_dim = 10\n",
    "arguments.disable_masking = 1 # 0 for disable mask, 1 for mask (unstructured)\n",
    "arguments.track_weights = 0\n",
    "arguments.enable_rewinding = 0\n",
    "arguments.growing_rate = 0.0000\n",
    "arguments.outer_layer_pruning = 1\n",
    "arguments.prune_criterion = \"SNIPit\"\n",
    "arguments.l0 = 0\n",
    "arguments.l0_reg = 1.0\n",
    "arguments.l1_reg = 0\n",
    "arguments.lp_reg = 0\n",
    "arguments.l2_reg = 5e-5\n",
    "arguments.hoyer_reg = 0.001\n",
    "arguments.N = 6000 # different for different dataset\n",
    "arguments.beta_ema = 0.999\n",
    "\n",
    "\n",
    "# define arguments for criterion\n",
    "arguments.pruning_limit = 0.5\n",
    "arguments.snip_steps = 6\n",
    "\n",
    "# not pre-trained model\n",
    "arguments.checkpoint_name = None\n",
    "arguments.checkpoint_model = None\n",
    "\n",
    "# dataset\n",
    "arguments.data_set = \"CIFAR10\"\n",
    "arguments.batch_size = 512\n",
    "arguments.mean = (0.4914, 0.4822, 0.4465)\n",
    "arguments.std = (0.2471, 0.2435, 0.2616)\n",
    "arguments.tuning = 0\n",
    "arguments.preload_all_data = 0\n",
    "arguments.random_shuffle_labels = 0\n",
    "\n",
    "# loss\n",
    "arguments.loss = \"CrossEntropy\"\n",
    "\n",
    "# optimizer\n",
    "arguments.optimizer = \"ADAM\"\n",
    "arguments.learning_rate = 2e-3\n",
    "\n",
    "# training\n",
    "arguments.save_freq = 1e6\n",
    "arguments.eval = 0\n",
    "arguments.train_scheme = \"DefaultTrainer\"\n",
    "arguments.seed = 1234\n",
    "arguments.epochs = 10\n",
    "\n",
    "arguments.grad_noise = 0\n",
    "arguments.grad_clip =10\n",
    "arguments.eval_freq = 1000\n",
    "arguments.max_training_minutes= 6120\n",
    "arguments.plot_weights_freq = 10\n",
    "arguments.prune_delay = 0\n",
    "arguments.prune_freq = 1\n",
    "arguments.rewind_to = 6\n",
    "\n",
    "arguments.skip_first_plot = 0\n",
    "arguments.disable_histograms = 0\n",
    "arguments.disable_saliency = 0\n",
    "arguments.disable_confusion = 0\n",
    "arguments.disable_weightplot = 0\n",
    "arguments.disable_netplot = 0\n",
    "arguments.disable_activations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 2022-04-17_19.12.53\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics()\n",
    "out = metrics.log_line\n",
    "print = out\n",
    "\n",
    "ensure_current_directory()\n",
    "global out \n",
    "out = metrics.log_line\n",
    "out(f\"starting at {get_date_stamp()}\")\n",
    "\n",
    "metrics._batch_size = arguments.batch_size\n",
    "metrics._eval_freq = arguments.eval_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = configure_device(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dim:10\n"
     ]
    }
   ],
   "source": [
    "# get model\n",
    "model: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR,arguments.model,\n",
    "        device=device,\n",
    "        hidden_dim = arguments.hidden_dim,\n",
    "        input_dim = arguments.input_dim,\n",
    "        output_dim = arguments.output_dim,\n",
    "        is_maskable=arguments.disable_masking,\n",
    "        is_tracking_weights=arguments.track_weights,\n",
    "        is_rewindable=arguments.enable_rewinding,\n",
    "        is_growable=arguments.growing_rate > 0,\n",
    "        outer_layer_pruning=arguments.outer_layer_pruning,\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments.outer_layer_pruning) and (\n",
    "                                           \"Structured\" in arguments.prune_criterion),\n",
    "        l0=arguments.l0,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        N=arguments.N,\n",
    "        beta_ema=arguments.beta_ema,\n",
    "        l2_reg=arguments.l2_reg\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get criterion\n",
    "criterion = find_right_model(\n",
    "        CRITERION_DIR,arguments.prune_criterion,\n",
    "        model=model,\n",
    "        limit=arguments.pruning_limit,\n",
    "        start=0.5,\n",
    "        steps=arguments.snip_steps,\n",
    "        device=arguments.device\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(arguments, metrics, model):\n",
    "    if (not (arguments.checkpoint_name is None)) and (not (arguments.checkpoint_model is None)):\n",
    "        path = os.path.join(RESULTS_DIR, arguments.checkpoint_name, MODELS_DIR, arguments.checkpoint_model)\n",
    "        state = DATA_MANAGER.load_python_obj(path)\n",
    "        try:\n",
    "            model.load_state_dict(state)\n",
    "        except KeyError as e:\n",
    "            print(list(state.keys()))\n",
    "            raise e\n",
    "        out(f\"Loaded checkpoint {arguments.checkpoint_name} from {arguments.checkpoint_model}\")\n",
    "\n",
    "# load pre-trained weights if specified\n",
    "load_checkpoint(arguments, metrics, model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean (0.4914, 0.4822, 0.4465)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_loader, test_loader = find_right_model(\n",
    "        DATASETS, arguments.data_set,\n",
    "        arguments=arguments,\n",
    "        mean=arguments.mean,\n",
    "        std=arguments.std\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loss function\n",
    "loss = find_right_model(\n",
    "        LOSS_DIR, arguments.loss,\n",
    "        device=device,\n",
    "        l1_reg=arguments.l1_reg,\n",
    "        lp_reg=arguments.lp_reg,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        hoyer_reg=arguments.hoyer_reg\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimizer\n",
    "optimizer = find_right_model(\n",
    "        OPTIMS, arguments.optimizer,\n",
    "        params=model.parameters(),\n",
    "        lr=arguments.learning_rate,\n",
    "        weight_decay=arguments.l2_reg if not arguments.l0 else 0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made datestamp: 2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234\n"
     ]
    }
   ],
   "source": [
    "if not arguments.eval:\n",
    "    # build trainer\n",
    "    run_name = f'_model={arguments.model}_dataset={arguments.data_set}_prune-criterion={arguments.prune_criterion}' + \\\n",
    "               f'_pruning-limit={arguments.pruning_limit}_train-scheme={arguments.train_scheme}_seed={arguments.seed}'\n",
    "    trainer = find_right_model(\n",
    "            TRAINERS_DIR, arguments.train_scheme,\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            arguments=arguments,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            metrics=metrics,\n",
    "            criterion=criterion,\n",
    "            run_name = run_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mStarted training\u001b[0m\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1728.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "36864.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "36864.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "36864.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "36864.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "73728.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "147456.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "8192.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "147456.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "147456.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "294912.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "589824.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "32768.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "589824.0\n",
      "pruning 302952 percentage 0.5136311848958334 length_nonzero 589824.0\n",
      "589824.0\n",
      "pruning 257752 percentage 0.4369981553819444 length_nonzero 589824.0\n",
      "1179648.0\n",
      "pruning 485660 percentage 0.4116990831163194 length_nonzero 1179648.0\n",
      "2359296.0\n",
      "pruning 1190684 percentage 0.5046776665581597 length_nonzero 2359296.0\n",
      "131072.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "2359296.0\n",
      "pruning 1567980 percentage 0.6645965576171875 length_nonzero 2359296.0\n",
      "2359296.0\n",
      "pruning 1248001 percentage 0.5289717780219184 length_nonzero 2359296.0\n",
      "5120.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "286872.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "332072.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "693988.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168612.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "791316.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111295.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "Saved results/2022-04-17_19.12.58_model=ResNet18_dataset=CIFAR10_prune-criterion=SNIPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "1720.0\n",
      "pruning 8 percentage 0.004629629629629629 length_nonzero 1728.0\n",
      "29373.0\n",
      "pruning 7491 percentage 0.20320638020833334 length_nonzero 36864.0\n",
      "29615.0\n",
      "pruning 7249 percentage 0.19664171006944445 length_nonzero 36864.0\n",
      "30014.0\n",
      "pruning 6850 percentage 0.1858181423611111 length_nonzero 36864.0\n",
      "29817.0\n",
      "pruning 7047 percentage 0.191162109375 length_nonzero 36864.0\n",
      "63018.0\n",
      "pruning 10710 percentage 0.145263671875 length_nonzero 73728.0\n",
      "102933.0\n",
      "pruning 44523 percentage 0.30194091796875 length_nonzero 147456.0\n",
      "7901.0\n",
      "pruning 291 percentage 0.0355224609375 length_nonzero 8192.0\n",
      "84474.0\n",
      "pruning 62982 percentage 0.4271240234375 length_nonzero 147456.0\n",
      "95597.0\n",
      "pruning 51859 percentage 0.3516913519965278 length_nonzero 147456.0\n",
      "213142.0\n",
      "pruning 81770 percentage 0.2772691514756944 length_nonzero 294912.0\n",
      "363052.0\n",
      "pruning 226772 percentage 0.3844740125868056 length_nonzero 589824.0\n",
      "29696.0\n",
      "pruning 3072 percentage 0.09375 length_nonzero 32768.0\n",
      "285661.0\n",
      "pruning 304163 percentage 0.5156843397352431 length_nonzero 589824.0\n",
      "331905.0\n",
      "pruning 257919 percentage 0.4372812906901042 length_nonzero 589824.0\n",
      "691673.0\n",
      "pruning 487975 percentage 0.41366153293185765 length_nonzero 1179648.0\n",
      "1168319.0\n",
      "pruning 1190977 percentage 0.5048018561469184 length_nonzero 2359296.0\n",
      "112583.0\n",
      "pruning 18489 percentage 0.14105987548828125 length_nonzero 131072.0\n",
      "783760.0\n",
      "pruning 1575536 percentage 0.6677992078993056 length_nonzero 2359296.0\n",
      "1111246.0\n",
      "pruning 1248050 percentage 0.5289925469292535 length_nonzero 2359296.0\n",
      "5085.0\n",
      "pruning 35 percentage 0.0068359375 length_nonzero 5120.0\n",
      "final percentage after snip: 0.0\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 0 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.1191406  |  2.5827172   |  2.3180045  | 0.1035731  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   65.8801051    |       567743488.0       |      11.4634221     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0304477     |\n",
      "Training... 97/98\n",
      "\n",
      "plotting..\n",
      "finished plotting\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 1 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.4492188  |  1.4774281   |  1.5776892  | 0.4343118  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   192.5845609   |       567743488.0       |      13.4590573     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0252280     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 2 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.5722656  |  1.1586647   |  1.1977763  | 0.5746898  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   194.0028025   |       567743488.0       |      13.7578883     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0256618     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 3 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.6777344  |  0.8835127   |  1.1744693  | 0.6230813  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   196.0553383   |       567743488.0       |      13.9332441     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0257143     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 4 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.7070312  |  0.8385662   |  0.9639197  | 0.6647116  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   196.0546557   |       567743488.0       |      14.0578147     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0257609     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 5 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.7480469  |  0.6875496   |  0.9487832  | 0.6893382  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   198.3574891   |       567743488.0       |      14.1545036     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0259371     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 6 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.8164062  |  0.5420224   |  0.7510330  | 0.7513500  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   199.7883278   |       567743488.0       |      14.2335374     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0262417     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 7 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.7988281  |  0.5684819   |  0.6197673  | 0.7948932  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   199.7169706   |       567743488.0       |      14.3003789     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0262509     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 8 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.8652344  |  0.4298150   |  0.6645547  | 0.7768899  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   200.1034186   |       567743488.0       |      14.3582918     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0262919     |\n",
      "Training... 97/98\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 9 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/98\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.8242188  |  0.4745658   |  0.6404415  | 0.7989200  |    0.0000000    |   0.0000000   |  0.0000000  |       19.0602786       |   200.5563403   |       567743488.0       |      14.4093828     \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |     231605248.0      |     0.0262359     |\n",
      "Training... 97/98\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8, device='cuda:0')\n",
      "tensor(7491, device='cuda:0')\n",
      "tensor(7249, device='cuda:0')\n",
      "tensor(6850, device='cuda:0')\n",
      "tensor(7047, device='cuda:0')\n",
      "tensor(10710, device='cuda:0')\n",
      "tensor(44523, device='cuda:0')\n",
      "tensor(291, device='cuda:0')\n",
      "tensor(62982, device='cuda:0')\n",
      "tensor(51859, device='cuda:0')\n",
      "tensor(81770, device='cuda:0')\n",
      "tensor(226772, device='cuda:0')\n",
      "tensor(3072, device='cuda:0')\n",
      "tensor(304163, device='cuda:0')\n",
      "tensor(257919, device='cuda:0')\n",
      "tensor(487975, device='cuda:0')\n",
      "tensor(1190977, device='cuda:0')\n",
      "tensor(18489, device='cuda:0')\n",
      "tensor(1575536, device='cuda:0')\n",
      "tensor(1248050, device='cuda:0')\n",
      "tensor(35, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "zero=0\n",
    "non_zero=0\n",
    "for weight in model.mask.values():\n",
    "    zero += torch.sum(weight==0).item()\n",
    "    non_zero += torch.sum(weight!=0).item()\n",
    "\n",
    "print(zero/(ze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]],\n",
       "\n",
       "         [[False, False, False],\n",
       "          [False, False, False],\n",
       "          [False, False, False]]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
