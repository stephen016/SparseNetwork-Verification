{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from asyncio import MultiLoopChildWatcher\n",
    "from doctest import OutputChecker\n",
    "\n",
    "from turtle import hideturtle\n",
    "import warnings\n",
    "\n",
    "from models import GeneralModel\n",
    "from models.statistics.Metrics import Metrics\n",
    "from utils.config_utils import *\n",
    "from utils.model_utils import *\n",
    "from utils.system_utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from models.networks.ConvertMLP import ConvertMLP2,ConvertMLP3\n",
    "\n",
    "from verify_utils.verify_utils import verify_single_image\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define arguments manually\n",
    "arguments = argparse.Namespace()\n",
    "# device\n",
    "arguments.device = \"cuda\"\n",
    "\n",
    "# define arguments for model\n",
    "#arguments.model = \"ResNet18\" # ResNet not supported for structured\n",
    "arguments.model = \"MLP2\"\n",
    "arguments.hidden_dim = 64\n",
    "#arguments.input_dim = None # for ResNet\n",
    "#arguments.input_dim = (1,1,1) # for LeNet5\n",
    "arguments.input_dim = (28,28) # for MNIST\n",
    "arguments.output_dim = 10\n",
    "arguments.disable_masking = 1 # 0 for disable mask, 1 for mask (unstructured)\n",
    "arguments.track_weights = 0\n",
    "arguments.enable_rewinding = 0\n",
    "arguments.growing_rate = 0.0000\n",
    "arguments.outer_layer_pruning = 0\n",
    "# arguments.prune_criterion = \"SNIPit\"  # unstructured\n",
    "\n",
    "arguments.prune_criterion = \"SNAPit\" # or SNAPit ... # structured\n",
    "arguments.l0 = 0\n",
    "arguments.l0_reg = 1.0\n",
    "arguments.l1_reg = 0\n",
    "arguments.lp_reg = 0\n",
    "arguments.l2_reg = 5e-5\n",
    "arguments.hoyer_reg = 0.001\n",
    "arguments.N = 6000 # different for different dataset\n",
    "arguments.beta_ema = 0.999\n",
    "\n",
    "\n",
    "# define arguments for criterion\n",
    "arguments.pruning_limit = 0.5\n",
    "arguments.snip_steps = 6\n",
    "\n",
    "# not pre-trained model\n",
    "arguments.checkpoint_name = None\n",
    "arguments.checkpoint_model = None\n",
    "\n",
    "# dataset\n",
    "arguments.data_set = \"MNIST\"\n",
    "arguments.batch_size = 512\n",
    "arguments.mean = (0.1307,)\n",
    "arguments.std = (0.3081,)\n",
    "arguments.tuning = 0\n",
    "arguments.preload_all_data = 0\n",
    "arguments.random_shuffle_labels = 0\n",
    "\n",
    "# loss\n",
    "arguments.loss = \"CrossEntropy\"\n",
    "\n",
    "# optimizer\n",
    "arguments.optimizer = \"ADAM\"\n",
    "arguments.learning_rate = 2e-3\n",
    "\n",
    "# training\n",
    "arguments.save_freq = 1e6\n",
    "arguments.eval = 0\n",
    "arguments.train_scheme = \"DefaultTrainer\"\n",
    "arguments.seed = 1234\n",
    "arguments.epochs = 5\n",
    "\n",
    "arguments.grad_noise = 0\n",
    "arguments.grad_clip =10\n",
    "arguments.eval_freq = 1000\n",
    "arguments.max_training_minutes= 6120\n",
    "arguments.plot_weights_freq = 50\n",
    "arguments.prune_delay = 0\n",
    "arguments.prune_freq = 1\n",
    "arguments.rewind_to = 6\n",
    "\n",
    "arguments.skip_first_plot = 0\n",
    "arguments.disable_histograms = 0\n",
    "arguments.disable_saliency = 0\n",
    "arguments.disable_confusion = 0\n",
    "arguments.disable_weightplot = 0\n",
    "arguments.disable_netplot = 0\n",
    "arguments.disable_activations = 0\n",
    "\n",
    "arguments.pruning_rate = 0\n",
    "# during training\n",
    "arguments.pruning_freq = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 2022-04-21_16.47.10\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics()\n",
    "out = metrics.log_line\n",
    "print = out\n",
    "\n",
    "ensure_current_directory()\n",
    "global out \n",
    "out = metrics.log_line\n",
    "out(f\"starting at {get_date_stamp()}\")\n",
    "\n",
    "metrics._batch_size = arguments.batch_size\n",
    "metrics._eval_freq = arguments.eval_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = configure_device(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "model: GeneralModel = find_right_model(\n",
    "        NETWORKS_DIR,arguments.model,\n",
    "        device=device,\n",
    "        hidden_dim = arguments.hidden_dim,\n",
    "        input_dim = arguments.input_dim,\n",
    "        output_dim = arguments.output_dim,\n",
    "        is_maskable=arguments.disable_masking,\n",
    "        is_tracking_weights=arguments.track_weights,\n",
    "        is_rewindable=arguments.enable_rewinding,\n",
    "        is_growable=arguments.growing_rate > 0,\n",
    "        outer_layer_pruning=arguments.outer_layer_pruning,\n",
    "        maintain_outer_mask_anyway=(\n",
    "                                       not arguments.outer_layer_pruning) and (\n",
    "                                           \"Structured\" in arguments.prune_criterion),\n",
    "        l0=arguments.l0,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        N=arguments.N,\n",
    "        beta_ema=arguments.beta_ema,\n",
    "        l2_reg=arguments.l2_reg\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key,param in model.named_parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get criterion\n",
    "criterion = find_right_model(\n",
    "        CRITERION_DIR,arguments.prune_criterion,\n",
    "        model=model,\n",
    "        limit=arguments.pruning_limit,\n",
    "        start=0.5,\n",
    "        steps=arguments.snip_steps,\n",
    "        device=arguments.device\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(arguments, metrics, model):\n",
    "    if (not (arguments.checkpoint_name is None)) and (not (arguments.checkpoint_model is None)):\n",
    "        path = os.path.join(RESULTS_DIR, arguments.checkpoint_name, MODELS_DIR, arguments.checkpoint_model)\n",
    "        state = DATA_MANAGER.load_python_obj(path)\n",
    "        try:\n",
    "            model.load_state_dict(state)\n",
    "        except KeyError as e:\n",
    "            print(list(state.keys()))\n",
    "            raise e\n",
    "        out(f\"Loaded checkpoint {arguments.checkpoint_name} from {arguments.checkpoint_model}\")\n",
    "\n",
    "# load pre-trained weights if specified\n",
    "load_checkpoint(arguments, metrics, model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean (0.1307,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_loader, test_loader = find_right_model(\n",
    "        DATASETS, arguments.data_set,\n",
    "        arguments=arguments,\n",
    "        mean=arguments.mean,\n",
    "        std=arguments.std\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loss function\n",
    "loss = find_right_model(\n",
    "        LOSS_DIR, arguments.loss,\n",
    "        device=device,\n",
    "        l1_reg=arguments.l1_reg,\n",
    "        lp_reg=arguments.lp_reg,\n",
    "        l0_reg=arguments.l0_reg,\n",
    "        hoyer_reg=arguments.hoyer_reg\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimizer\n",
    "optimizer = find_right_model(\n",
    "        OPTIMS, arguments.optimizer,\n",
    "        params=model.parameters(),\n",
    "        lr=arguments.learning_rate,\n",
    "        weight_decay=arguments.l2_reg if not arguments.l0 else 0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made datestamp: 2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234\n"
     ]
    }
   ],
   "source": [
    "if not arguments.eval:\n",
    "    # build trainer\n",
    "    run_name = f'_model={arguments.model}_dataset={arguments.data_set}_prune-criterion={arguments.prune_criterion}' + \\\n",
    "               f'_pruning-limit={arguments.pruning_limit}_train-scheme={arguments.train_scheme}_seed={arguments.seed}'\n",
    "    trainer = find_right_model(\n",
    "            TRAINERS_DIR, arguments.train_scheme,\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            arguments=arguments,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            metrics=metrics,\n",
    "            criterion=criterion,\n",
    "            run_name = run_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mStarted training\u001b[0m\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 25088 percentage 0.5 length_nonzero 50176\n",
      "pruning 320 percentage 0.5 length_nonzero 640\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=32.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=32.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.5\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 784 percentage 0.03125 length_nonzero 25088\n",
      "pruning 10 percentage 0.03125 length_nonzero 320\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.03125\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "Saved results/2022-04-21_16.47.14_model=MLP2_dataset=MNIST_prune-criterion=SNAPit_pruning-limit=0.5_train-scheme=DefaultTrainer_seed=1234/output/scores\n",
      "pruning 0 percentage 0.0 length_nonzero 24304\n",
      "pruning 0 percentage 0.0 length_nonzero 310\n",
      "  (layers): Sequential(\n",
      "    (0): ContainerLinear(in_features=784, out_features=31.0, bias=True)\n",
      "    (2): ContainerLinear(in_features=31.0, out_features=10, bias=True)\n",
      "final percentage after snap: 0.0\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 0 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.0820312  |  2.6976888   |  2.3130438  | 0.1760455  |    0.5156250    |   0.5156250   |  0.2624760  |       13.6375339       |    0.7036328    |      24903.0000000      |      7.1055216      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |    450560.0000000    |     0.0241276     |\n",
      "Training... 117/118\n",
      "\n",
      "plotting..\n",
      "finished plotting\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 1 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9179688  |  0.3008573   |  0.2755278  | 0.9195657  |    0.5156250    |   0.5156250   |  0.6607499  |       13.6375339       |    2.5360102    |      24903.0000000      |      9.1810686      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |    450560.0000000    |     0.0063613     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 2 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9453125  |  0.2042911   |  0.2060881  | 0.9380744  |    0.5156250    |   0.5156250   |  0.6654672  |       13.6375339       |    1.7405463    |      24903.0000000      |      9.4802700      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |    450560.0000000    |     0.0065497     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 3 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9433594  |  0.1711224   |  0.1729033  | 0.9496266  |    0.5156250    |   0.5156250   |  0.6683510  |       13.6375339       |    2.1088784    |      24903.0000000      |      9.6557500      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |    450560.0000000    |     0.0067032     |\n",
      "Training... 117/118\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mEPOCH 4 \u001b[0m \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training... 0/118\n",
      "\n",
      "Evaluating... 19/20\n",
      "\n",
      "$  acc/train  |  loss/train  |  loss/test  |  acc/test  |  sparse/weight  |  sparse/node  |  sparse/hm  |  sparse/log_disk_size  |  time/gpu_time  |  time/flops_per_sample  |  time/flops_log_cum \n",
      "$  0.9492188  |  0.1540006   |  0.1567740  | 0.9534639  |    0.5156250    |   0.5156250   |  0.6692989  |       13.6375339       |    2.3491499    |      24903.0000000      |      9.7803828      \n",
      "$ |  cuda/ram_footprint  |  time/batch_time  |  \n",
      "$ |    450560.0000000    |     0.0064929     |\n",
      "Training... 117/118\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 784])\n",
      "torch.Size([31])\n",
      "torch.Size([10, 31])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for key,param in model.named_parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ConvertMLP2.fuse of ConvertMLP2(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=31, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=31, out_features=10, bias=True)\n",
       "  )\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change to cpu and eval mode\n",
    "model.to(\"cpu\").eval()\n",
    "\n",
    "# get the model parameters\n",
    "state = model.state_dict()\n",
    "# convet the model to a quantizable model\n",
    "q_model= ConvertMLP2(model)\n",
    "# load previous parameter\n",
    "q_model.load_state_dict(state)\n",
    "# set quantization config\n",
    "q_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "# fuse_model\n",
    "q_model.fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.5847,  -5.2044,  -2.3644,  ..., -11.3830,   1.3380,  -4.3807],\n",
       "        [  2.5568,  -5.2369,   4.1925,  ...,  -2.5161,   1.5116,  -1.6804],\n",
       "        [ -1.7397,  -7.6789,  -2.3339,  ..., -10.4554,   2.9656,  -6.0093],\n",
       "        ...,\n",
       "        [ -1.2047, -10.4999,  -7.7756,  ...,  -2.0436,   0.8609,   5.6215],\n",
       "        [ -5.9612,  -5.1753,  -0.5726,  ...,  12.3875,  -0.4170,   2.5765],\n",
       "        [  0.3165,  -7.2766,  -4.6405,  ...,  -5.9404,  -4.0411,  -1.6828]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use calibrate date to calibrate model\n",
    "model_prepared = torch.quantization.prepare(q_model)\n",
    "cali_data,label=next(iter(train_loader))\n",
    "model_prepared(cali_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to int8\n",
    "model_int8 = torch.quantization.convert(model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.5895,  -5.0109,  -2.3581,  ..., -11.2009,   1.1790,  -4.4214],\n",
       "        [  2.3581,  -5.3057,   4.1266,  ...,  -2.6528,   1.4738,  -1.4738],\n",
       "        [ -1.7686,  -7.6638,  -2.3581,  ..., -10.3166,   3.2424,  -5.8952],\n",
       "        ...,\n",
       "        [ -1.1790, -10.3166,  -7.3690,  ...,  -2.3581,   1.1790,   5.6005],\n",
       "        [ -5.6005,  -5.0109,  -0.2948,  ...,  12.3799,  -0.2948,   2.3581],\n",
       "        [  0.2948,  -7.0743,  -4.7162,  ...,  -6.1900,  -4.1266,  -1.4738]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8(cali_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvertMLP2(\n",
       "  (layers): Sequential(\n",
       "    (0): QuantizedLinear(in_features=784, out_features=31, scale=0.4623158276081085, zero_point=78, qscheme=torch.per_channel_affine)\n",
       "    (1): ReLU()\n",
       "    (2): QuantizedLinear(in_features=31, out_features=10, scale=0.29476067423820496, zero_point=68, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0254]), zero_point=tensor([16]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the model size\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32model  \t Size (KB): 100.127\n",
      "model:  quantized  \t Size (KB): 29.691\n"
     ]
    }
   ],
   "source": [
    "size_model_fp32 = print_size_of_model(model,label=\"fp32model\")\n",
    "size_model_int8 = print_size_of_model(model_int8,label=\"quantized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to verify a quantized model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765c16519b424b8397cf5ae0ae682154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label=next(iter(test_loader))\n",
    "img_test = img[0].squeeze().to(device)\n",
    "model.to(device)\n",
    "img,label=verify_single_image(model,img_test,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.value.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"perturbed prediction: {label.value.argmax()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
